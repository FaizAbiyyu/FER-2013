{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9108,
     "status": "ok",
     "timestamp": 1524304291827,
     "user": {
      "displayName": "Łukasz Zawieska",
      "photoUrl": "//lh4.googleusercontent.com/-SOS7Ol5qfEA/AAAAAAAAAAI/AAAAAAAABh4/xJ9cAj7pBag/s50-c-k-no/photo.jpg",
      "userId": "112181072187986880314"
     },
     "user_tz": -120
    },
    "id": "M3esxoVFVqZ4",
    "outputId": "6a4068d4-30e4-4756-c94a-59a81bb49645"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Sequential, load_model\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Activation, Dropout, Flatten, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import  RandomNormal\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from skimage import feature\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "from keras.layers import Input, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Checking if GPU is available\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and preprocessing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menghitung LBP pada satu gambar\n",
    "def calculate_lbp_image(img):\n",
    "    lbp_image = local_binary_pattern(img, 8, 1, method='uniform')\n",
    "    return lbp_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1763,
     "status": "ok",
     "timestamp": 1524231801053,
     "user": {
      "displayName": "Łukasz Zawieska",
      "photoUrl": "//lh4.googleusercontent.com/-SOS7Ol5qfEA/AAAAAAAAAAI/AAAAAAAABh4/xJ9cAj7pBag/s50-c-k-no/photo.jpg",
      "userId": "112181072187986880314"
     },
     "user_tz": -120
    },
    "id": "MoLNdrj2Us6r",
    "outputId": "ce45654a-3fe5-400b-c639-9f1531306be6"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../fer2013.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building LBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ekstraksi fitur LBP dan simpan dalam list\n",
    "lbp_features = []\n",
    "for i in range(len(data)):\n",
    "    pixels = np.array(data['pixels'].iloc[i].split(' '), dtype=int)\n",
    "    img = pixels.reshape(48, 48)\n",
    "    lbp_image = calculate_lbp_image(img)\n",
    "    lbp_features.append(lbp_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konversi list ke array\n",
    "lbp_features = np.array(lbp_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konversi label emosi menjadi one-hot encoding\n",
    "encoder = LabelEncoder()\n",
    "labels = encoder.fit_transform(data['emotion'])\n",
    "labels = tf.keras.utils.to_categorical(labels, num_classes=7)  # Ubah menjadi 7 karena ada 7 emosi dalam dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagi data menjadi set pelatihan dan validasi\n",
    "X_train, X_val, y_train, y_val = train_test_split(lbp_features, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fvVfvlpXUs65"
   },
   "outputs": [],
   "source": [
    "# Constructing CNN structure\n",
    "\n",
    "# VGG16 arsitektur\n",
    "# Membuat model VGG16 dengan citra grayscale\n",
    "model = Sequential()\n",
    "\n",
    "# Layer 1 (grayscale input)\n",
    "model.add(Conv2D(64, (3, 3), input_shape=(48, 48, 1), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# Layer 2\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# Layer 3\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# Layer 4\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# Layer 5\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation='softmax'))  # 7 classes for ImageNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "f0DK4TmHUs6-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 48, 48, 64)        640       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 48, 48, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 24, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 6, 6, 512)         1180160   \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 3, 3, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 1, 1, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              2101248   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 28679     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,624,775\n",
      "Trainable params: 33,624,775\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Tampilkan ringkasan model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1074
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 292308,
     "status": "ok",
     "timestamp": 1523867019418,
     "user": {
      "displayName": "Łukasz Zawieska",
      "photoUrl": "//lh4.googleusercontent.com/-SOS7Ol5qfEA/AAAAAAAAAAI/AAAAAAAABh4/xJ9cAj7pBag/s50-c-k-no/photo.jpg",
      "userId": "112181072187986880314"
     },
     "user_tz": -120
    },
    "id": "WqJ6x2nPUs7A",
    "outputId": "a3b7d09b-ed7c-49cb-8f06-0c70cc13fac9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\.conda\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "455/455 [==============================] - 43s 83ms/step - loss: 2.0082 - accuracy: 0.2468 - val_loss: 1.7945 - val_accuracy: 0.2517\n",
      "Epoch 2/50\n",
      "455/455 [==============================] - 36s 80ms/step - loss: 1.7948 - accuracy: 0.2530 - val_loss: 1.7823 - val_accuracy: 0.2622\n",
      "Epoch 3/50\n",
      "455/455 [==============================] - 37s 81ms/step - loss: 1.7470 - accuracy: 0.2828 - val_loss: 1.7161 - val_accuracy: 0.2960\n",
      "Epoch 4/50\n",
      "455/455 [==============================] - 37s 81ms/step - loss: 1.6110 - accuracy: 0.3674 - val_loss: 1.5898 - val_accuracy: 0.3718\n",
      "Epoch 5/50\n",
      "455/455 [==============================] - 37s 81ms/step - loss: 1.4380 - accuracy: 0.4503 - val_loss: 1.6102 - val_accuracy: 0.3783\n",
      "Epoch 6/50\n",
      "455/455 [==============================] - 37s 81ms/step - loss: 1.1193 - accuracy: 0.5813 - val_loss: 1.7620 - val_accuracy: 0.3737\n",
      "Epoch 7/50\n",
      "455/455 [==============================] - 37s 81ms/step - loss: 0.6937 - accuracy: 0.7522 - val_loss: 2.0751 - val_accuracy: 0.3845\n",
      "Epoch 8/50\n",
      "455/455 [==============================] - 37s 81ms/step - loss: 0.4031 - accuracy: 0.8658 - val_loss: 2.3494 - val_accuracy: 0.3885\n",
      "Epoch 9/50\n",
      "455/455 [==============================] - 37s 82ms/step - loss: 0.2682 - accuracy: 0.9154 - val_loss: 2.6188 - val_accuracy: 0.3920\n",
      "Epoch 10/50\n",
      "455/455 [==============================] - 37s 82ms/step - loss: 0.2023 - accuracy: 0.9396 - val_loss: 2.6057 - val_accuracy: 0.3861\n",
      "Epoch 11/50\n",
      "455/455 [==============================] - 37s 82ms/step - loss: 0.1611 - accuracy: 0.9552 - val_loss: 3.2988 - val_accuracy: 0.3944\n",
      "Epoch 12/50\n",
      "455/455 [==============================] - 37s 82ms/step - loss: 0.1270 - accuracy: 0.9653 - val_loss: 3.3011 - val_accuracy: 0.3786\n",
      "Epoch 13/50\n",
      "455/455 [==============================] - 37s 82ms/step - loss: 0.1024 - accuracy: 0.9718 - val_loss: 2.6342 - val_accuracy: 0.3796\n",
      "Epoch 14/50\n",
      "455/455 [==============================] - 37s 82ms/step - loss: 0.1056 - accuracy: 0.9712 - val_loss: 3.4554 - val_accuracy: 0.3858\n",
      "Epoch 15/50\n",
      "455/455 [==============================] - 37s 82ms/step - loss: 0.0918 - accuracy: 0.9762 - val_loss: 3.3851 - val_accuracy: 0.3786\n",
      "Epoch 16/50\n",
      "455/455 [==============================] - 37s 82ms/step - loss: 0.0915 - accuracy: 0.9758 - val_loss: 3.4732 - val_accuracy: 0.3737\n",
      "Epoch 17/50\n",
      "455/455 [==============================] - 37s 82ms/step - loss: 0.0895 - accuracy: 0.9782 - val_loss: 3.1630 - val_accuracy: 0.3755\n",
      "Epoch 18/50\n",
      "455/455 [==============================] - 37s 82ms/step - loss: 0.0784 - accuracy: 0.9809 - val_loss: 3.3291 - val_accuracy: 0.3786\n",
      "Epoch 19/50\n",
      "455/455 [==============================] - 37s 82ms/step - loss: 0.0681 - accuracy: 0.9834 - val_loss: 3.3849 - val_accuracy: 0.3786\n",
      "Epoch 20/50\n",
      "455/455 [==============================] - 37s 82ms/step - loss: 0.0610 - accuracy: 0.9847 - val_loss: 3.8312 - val_accuracy: 0.3811\n",
      "Epoch 21/50\n",
      "455/455 [==============================] - 38s 82ms/step - loss: 0.0723 - accuracy: 0.9817 - val_loss: 3.8445 - val_accuracy: 0.3786\n",
      "Epoch 22/50\n",
      "455/455 [==============================] - 38s 83ms/step - loss: 0.0681 - accuracy: 0.9825 - val_loss: 3.4513 - val_accuracy: 0.3746\n",
      "Epoch 23/50\n",
      "455/455 [==============================] - 38s 83ms/step - loss: 0.0771 - accuracy: 0.9827 - val_loss: 3.6421 - val_accuracy: 0.3721\n",
      "Epoch 24/50\n",
      "455/455 [==============================] - 38s 83ms/step - loss: 0.0723 - accuracy: 0.9840 - val_loss: 3.3489 - val_accuracy: 0.3820\n",
      "Epoch 25/50\n",
      "455/455 [==============================] - 38s 83ms/step - loss: 0.0568 - accuracy: 0.9863 - val_loss: 3.6144 - val_accuracy: 0.3882\n",
      "Epoch 26/50\n",
      "455/455 [==============================] - 38s 83ms/step - loss: 0.0597 - accuracy: 0.9868 - val_loss: 3.8547 - val_accuracy: 0.3839\n",
      "Epoch 27/50\n",
      "455/455 [==============================] - 38s 83ms/step - loss: 0.0622 - accuracy: 0.9865 - val_loss: 3.3916 - val_accuracy: 0.3786\n",
      "Epoch 28/50\n",
      "455/455 [==============================] - 38s 83ms/step - loss: 0.0535 - accuracy: 0.9881 - val_loss: 4.7936 - val_accuracy: 0.3947\n",
      "Epoch 29/50\n",
      "455/455 [==============================] - 38s 83ms/step - loss: 0.0585 - accuracy: 0.9873 - val_loss: 4.3261 - val_accuracy: 0.3759\n",
      "Epoch 30/50\n",
      "455/455 [==============================] - 38s 83ms/step - loss: 0.0510 - accuracy: 0.9880 - val_loss: 4.1763 - val_accuracy: 0.3771\n",
      "Epoch 31/50\n",
      "455/455 [==============================] - 37s 82ms/step - loss: 0.0567 - accuracy: 0.9888 - val_loss: 4.2599 - val_accuracy: 0.3765\n",
      "Epoch 32/50\n",
      "455/455 [==============================] - 37s 82ms/step - loss: 0.0612 - accuracy: 0.9847 - val_loss: 4.7472 - val_accuracy: 0.3768\n",
      "Epoch 33/50\n",
      "455/455 [==============================] - 37s 82ms/step - loss: 0.0570 - accuracy: 0.9885 - val_loss: 4.3989 - val_accuracy: 0.3693\n",
      "Epoch 34/50\n",
      "455/455 [==============================] - 38s 83ms/step - loss: 0.0509 - accuracy: 0.9883 - val_loss: 4.2556 - val_accuracy: 0.3752\n",
      "Epoch 35/50\n",
      "455/455 [==============================] - 38s 83ms/step - loss: 0.0427 - accuracy: 0.9911 - val_loss: 4.8166 - val_accuracy: 0.3672\n",
      "Epoch 36/50\n",
      "455/455 [==============================] - 37s 82ms/step - loss: 0.0509 - accuracy: 0.9894 - val_loss: 4.6750 - val_accuracy: 0.3765\n",
      "Epoch 37/50\n",
      "455/455 [==============================] - 38s 82ms/step - loss: 0.0476 - accuracy: 0.9902 - val_loss: 3.7117 - val_accuracy: 0.3728\n",
      "Epoch 38/50\n",
      "455/455 [==============================] - 38s 82ms/step - loss: 0.0380 - accuracy: 0.9916 - val_loss: 4.7298 - val_accuracy: 0.3613\n",
      "Epoch 39/50\n",
      "455/455 [==============================] - 37s 82ms/step - loss: 0.0426 - accuracy: 0.9921 - val_loss: 4.8232 - val_accuracy: 0.3706\n",
      "Epoch 40/50\n",
      "455/455 [==============================] - 37s 82ms/step - loss: 0.0607 - accuracy: 0.9885 - val_loss: 4.4504 - val_accuracy: 0.3752\n",
      "Epoch 41/50\n",
      "455/455 [==============================] - 38s 82ms/step - loss: 0.0670 - accuracy: 0.9864 - val_loss: 4.2521 - val_accuracy: 0.3644\n",
      "Epoch 42/50\n",
      "455/455 [==============================] - 38s 83ms/step - loss: 0.0619 - accuracy: 0.9872 - val_loss: 4.4366 - val_accuracy: 0.3743\n",
      "Epoch 43/50\n",
      "455/455 [==============================] - 38s 83ms/step - loss: 0.0607 - accuracy: 0.9879 - val_loss: 3.7496 - val_accuracy: 0.3793\n",
      "Epoch 44/50\n",
      "455/455 [==============================] - 38s 82ms/step - loss: 0.0418 - accuracy: 0.9917 - val_loss: 3.9180 - val_accuracy: 0.3669\n",
      "Epoch 45/50\n",
      "455/455 [==============================] - 38s 83ms/step - loss: 0.0474 - accuracy: 0.9904 - val_loss: 4.2954 - val_accuracy: 0.3814\n",
      "Epoch 46/50\n",
      "455/455 [==============================] - 38s 82ms/step - loss: 0.0339 - accuracy: 0.9932 - val_loss: 3.9415 - val_accuracy: 0.3734\n",
      "Epoch 47/50\n",
      "455/455 [==============================] - 37s 82ms/step - loss: 0.0489 - accuracy: 0.9897 - val_loss: 3.9999 - val_accuracy: 0.3703\n",
      "Epoch 48/50\n",
      "455/455 [==============================] - 37s 82ms/step - loss: 0.0342 - accuracy: 0.9933 - val_loss: 4.4593 - val_accuracy: 0.3675\n",
      "Epoch 49/50\n",
      "455/455 [==============================] - 38s 82ms/step - loss: 0.0452 - accuracy: 0.9910 - val_loss: 6.0919 - val_accuracy: 0.3721\n",
      "Epoch 50/50\n",
      "455/455 [==============================] - 38s 83ms/step - loss: 0.0525 - accuracy: 0.9901 - val_loss: 4.9663 - val_accuracy: 0.3715\n"
     ]
    }
   ],
   "source": [
    "# # Compiling model\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "# # Specifying parameters for Data Augmentation\n",
    "# datagen = ImageDataGenerator(\n",
    "#     featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "#     samplewise_center=False,  # set each sample mean to 0\n",
    "#     featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "#     samplewise_std_normalization=False,  # divide each input by its std\n",
    "#     zca_whitening=False,  # apply ZCA whitening\n",
    "#     rotation_range=40,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "#     width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "#     height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "#     horizontal_flip=True,  # randomly flip images\n",
    "#     vertical_flip=False,\n",
    "#     zoom_range = 0.05)  # zoom images in range [1 - zoom_range, 1+ zoom_range]\n",
    "\n",
    "# datagen.fit(X_train)\n",
    "\n",
    "# history = model.fit_generator(datagen.flow(X_train, y_train,\n",
    "#                     batch_size=32),\n",
    "#                     epochs=10,  # Mengganti nb_epoch menjadi epochs\n",
    "#                     validation_data=(X_val, y_val),\n",
    "#                     steps_per_epoch=X_train.shape[0] // 32,  # Menggunakan // untuk pembagian bulat\n",
    "#                     )\n",
    "\n",
    "# # pd.DataFrame(history.history).to_csv(\"history.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "449/449 [==============================] - 34s 72ms/step - loss: 1.8126 - accuracy: 0.2516 - val_loss: 1.8102 - val_accuracy: 0.2459\n",
      "Epoch 2/100\n",
      "449/449 [==============================] - 33s 73ms/step - loss: 1.8126 - accuracy: 0.2516 - val_loss: 1.8102 - val_accuracy: 0.2459\n",
      "Epoch 3/100\n",
      "449/449 [==============================] - 33s 73ms/step - loss: 1.8124 - accuracy: 0.2516 - val_loss: 1.8102 - val_accuracy: 0.2459\n",
      "Epoch 4/100\n",
      "449/449 [==============================] - 33s 73ms/step - loss: 1.8116 - accuracy: 0.2516 - val_loss: 1.8113 - val_accuracy: 0.2459\n",
      "Epoch 5/100\n",
      "449/449 [==============================] - 33s 74ms/step - loss: 1.8117 - accuracy: 0.2516 - val_loss: 1.8096 - val_accuracy: 0.2459\n",
      "Epoch 6/100\n",
      "449/449 [==============================] - 33s 74ms/step - loss: 1.8124 - accuracy: 0.2516 - val_loss: 1.8097 - val_accuracy: 0.2459\n",
      "Epoch 7/100\n",
      "449/449 [==============================] - 33s 74ms/step - loss: 1.8122 - accuracy: 0.2516 - val_loss: 1.8105 - val_accuracy: 0.2459\n",
      "Epoch 8/100\n",
      "449/449 [==============================] - 33s 74ms/step - loss: 1.8117 - accuracy: 0.2516 - val_loss: 1.8101 - val_accuracy: 0.2459\n",
      "Epoch 9/100\n",
      "449/449 [==============================] - 34s 75ms/step - loss: 1.8122 - accuracy: 0.2516 - val_loss: 1.8105 - val_accuracy: 0.2459\n",
      "Epoch 10/100\n",
      "449/449 [==============================] - 34s 75ms/step - loss: 1.8117 - accuracy: 0.2516 - val_loss: 1.8099 - val_accuracy: 0.2459\n",
      "Epoch 11/100\n",
      "449/449 [==============================] - 34s 75ms/step - loss: 1.8118 - accuracy: 0.2516 - val_loss: 1.8105 - val_accuracy: 0.2459\n",
      "Epoch 12/100\n",
      "449/449 [==============================] - 34s 75ms/step - loss: 1.8119 - accuracy: 0.2516 - val_loss: 1.8095 - val_accuracy: 0.2459\n",
      "Epoch 13/100\n",
      "449/449 [==============================] - 34s 75ms/step - loss: 1.8117 - accuracy: 0.2516 - val_loss: 1.8096 - val_accuracy: 0.2459\n",
      "Epoch 14/100\n",
      "449/449 [==============================] - 34s 75ms/step - loss: 1.8115 - accuracy: 0.2516 - val_loss: 1.8099 - val_accuracy: 0.2459\n",
      "Epoch 15/100\n",
      "449/449 [==============================] - 34s 75ms/step - loss: 1.8121 - accuracy: 0.2516 - val_loss: 1.8097 - val_accuracy: 0.2459\n",
      "Epoch 16/100\n",
      "449/449 [==============================] - 34s 75ms/step - loss: 1.8120 - accuracy: 0.2516 - val_loss: 1.8100 - val_accuracy: 0.2459\n",
      "Epoch 17/100\n",
      "449/449 [==============================] - 34s 75ms/step - loss: 1.8116 - accuracy: 0.2516 - val_loss: 1.8098 - val_accuracy: 0.2459\n",
      "Epoch 18/100\n",
      "449/449 [==============================] - 34s 75ms/step - loss: 1.8122 - accuracy: 0.2516 - val_loss: 1.8103 - val_accuracy: 0.2459\n",
      "Epoch 19/100\n",
      "449/449 [==============================] - 34s 75ms/step - loss: 1.8116 - accuracy: 0.2516 - val_loss: 1.8102 - val_accuracy: 0.2459\n",
      "Epoch 20/100\n",
      "449/449 [==============================] - 34s 75ms/step - loss: 1.8119 - accuracy: 0.2516 - val_loss: 1.8099 - val_accuracy: 0.2459\n",
      "Epoch 21/100\n",
      "449/449 [==============================] - 34s 75ms/step - loss: 1.8121 - accuracy: 0.2516 - val_loss: 1.8101 - val_accuracy: 0.2459\n",
      "Epoch 22/100\n",
      "449/449 [==============================] - 34s 76ms/step - loss: 1.8119 - accuracy: 0.2516 - val_loss: 1.8104 - val_accuracy: 0.2459\n",
      "Epoch 23/100\n",
      "449/449 [==============================] - 34s 76ms/step - loss: 1.8117 - accuracy: 0.2516 - val_loss: 1.8097 - val_accuracy: 0.2459\n",
      "Epoch 24/100\n",
      "449/449 [==============================] - 34s 75ms/step - loss: 1.8122 - accuracy: 0.2516 - val_loss: 1.8096 - val_accuracy: 0.2459\n",
      "Epoch 25/100\n",
      "449/449 [==============================] - 34s 75ms/step - loss: 1.8116 - accuracy: 0.2516 - val_loss: 1.8100 - val_accuracy: 0.2459\n",
      "Epoch 26/100\n",
      "449/449 [==============================] - 34s 76ms/step - loss: 1.8118 - accuracy: 0.2516 - val_loss: 1.8101 - val_accuracy: 0.2459\n",
      "Epoch 27/100\n",
      "449/449 [==============================] - 34s 75ms/step - loss: 1.8120 - accuracy: 0.2516 - val_loss: 1.8099 - val_accuracy: 0.2459\n",
      "Epoch 28/100\n",
      "449/449 [==============================] - 34s 76ms/step - loss: 1.8115 - accuracy: 0.2516 - val_loss: 1.8097 - val_accuracy: 0.2459\n",
      "Epoch 29/100\n",
      "449/449 [==============================] - 34s 76ms/step - loss: 1.8117 - accuracy: 0.2516 - val_loss: 1.8099 - val_accuracy: 0.2459\n",
      "Epoch 30/100\n",
      "449/449 [==============================] - 34s 76ms/step - loss: 1.8115 - accuracy: 0.2516 - val_loss: 1.8097 - val_accuracy: 0.2459\n",
      "Epoch 31/100\n",
      "449/449 [==============================] - 34s 76ms/step - loss: 1.8117 - accuracy: 0.2516 - val_loss: 1.8100 - val_accuracy: 0.2459\n",
      "Epoch 32/100\n",
      "449/449 [==============================] - 34s 75ms/step - loss: 1.8117 - accuracy: 0.2516 - val_loss: 1.8097 - val_accuracy: 0.2459\n",
      "Epoch 33/100\n",
      "449/449 [==============================] - 34s 75ms/step - loss: 1.8118 - accuracy: 0.2516 - val_loss: 1.8098 - val_accuracy: 0.2459\n",
      "Epoch 34/100\n",
      "449/449 [==============================] - 34s 75ms/step - loss: 1.8114 - accuracy: 0.2516 - val_loss: 1.8097 - val_accuracy: 0.2459\n",
      "Epoch 35/100\n",
      "449/449 [==============================] - 34s 76ms/step - loss: 1.8115 - accuracy: 0.2516 - val_loss: 1.8097 - val_accuracy: 0.2459\n",
      "Epoch 36/100\n",
      "449/449 [==============================] - 34s 76ms/step - loss: 1.8115 - accuracy: 0.2516 - val_loss: 1.8102 - val_accuracy: 0.2459\n",
      "Epoch 37/100\n",
      "449/449 [==============================] - 34s 75ms/step - loss: 1.8115 - accuracy: 0.2516 - val_loss: 1.8099 - val_accuracy: 0.2459\n",
      "Epoch 38/100\n",
      "449/449 [==============================] - 34s 76ms/step - loss: 1.8114 - accuracy: 0.2516 - val_loss: 1.8106 - val_accuracy: 0.2459\n",
      "Epoch 39/100\n",
      "449/449 [==============================] - 34s 75ms/step - loss: 1.8112 - accuracy: 0.2516 - val_loss: 1.8103 - val_accuracy: 0.2459\n",
      "Epoch 40/100\n",
      "449/449 [==============================] - 34s 76ms/step - loss: 1.8114 - accuracy: 0.2516 - val_loss: 1.8101 - val_accuracy: 0.2459\n",
      "Epoch 41/100\n",
      "449/449 [==============================] - 34s 76ms/step - loss: 1.8117 - accuracy: 0.2516 - val_loss: 1.8099 - val_accuracy: 0.2459\n",
      "Epoch 42/100\n",
      "449/449 [==============================] - 34s 76ms/step - loss: 1.8115 - accuracy: 0.2516 - val_loss: 1.8099 - val_accuracy: 0.2459\n",
      "Epoch 43/100\n",
      "449/449 [==============================] - 34s 75ms/step - loss: 1.8117 - accuracy: 0.2516 - val_loss: 1.8098 - val_accuracy: 0.2459\n",
      "Epoch 44/100\n",
      "449/449 [==============================] - 34s 75ms/step - loss: 1.8114 - accuracy: 0.2516 - val_loss: 1.8097 - val_accuracy: 0.2459\n",
      "Epoch 45/100\n",
      "449/449 [==============================] - 34s 75ms/step - loss: 1.8114 - accuracy: 0.2516 - val_loss: 1.8098 - val_accuracy: 0.2459\n",
      "Epoch 46/100\n",
      "449/449 [==============================] - 34s 75ms/step - loss: 1.8114 - accuracy: 0.2516 - val_loss: 1.8102 - val_accuracy: 0.2459\n",
      "Epoch 47/100\n",
      "449/449 [==============================] - 34s 75ms/step - loss: 1.8115 - accuracy: 0.2516 - val_loss: 1.8099 - val_accuracy: 0.2459\n",
      "Epoch 48/100\n",
      "449/449 [==============================] - 34s 75ms/step - loss: 1.8116 - accuracy: 0.2516 - val_loss: 1.8100 - val_accuracy: 0.2459\n",
      "Epoch 49/100\n",
      "449/449 [==============================] - 34s 77ms/step - loss: 1.8113 - accuracy: 0.2516 - val_loss: 1.8099 - val_accuracy: 0.2459\n",
      "Epoch 50/100\n",
      "449/449 [==============================] - ETA: 0s - loss: 1.8113 - accuracy: 0.2516"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m X_val \u001b[38;5;241m=\u001b[39m X_val\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Latih model dengan data LBP\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py:1606\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[0;32m   1593\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m   1594\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1604\u001b[0m         steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution,\n\u001b[0;32m   1605\u001b[0m     )\n\u001b[1;32m-> 1606\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1608\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1609\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1611\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1615\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1617\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1618\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1619\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1620\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1621\u001b[0m }\n\u001b[0;32m   1622\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py:1947\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1943\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1944\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1945\u001b[0m ):\n\u001b[0;32m   1946\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 1947\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1949\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Reshape data LBP untuk memenuhi input model\n",
    "X_train = X_train.reshape(-1, 48, 48, 1)\n",
    "X_val = X_val.reshape(-1, 48, 48, 1)\n",
    "\n",
    "# Latih model dengan data LBP\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpan model ke dalam file\n",
    "# final_model.save(\"LBPVGG16.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading best model and exploring the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"LBPVGG16.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "909/909 [==============================] - 77s 84ms/step - loss: 0.0242 - accuracy: 0.9961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.024201760068535805, 0.9960781335830688]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.evaluate([X_train, lbp_images_train], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "909/909 [==============================] - 62s 68ms/step - loss: 0.0242 - accuracy: 0.9961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.024201760068535805, 0.9960781335830688]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([X_train, lbp_images_train], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 42s 371ms/step - loss: 4.8835 - accuracy: 0.3845\n",
      "909/909 [==============================] - 326s 358ms/step - loss: 0.0242 - accuracy: 0.9961\n"
     ]
    }
   ],
   "source": [
    "test_evaluation = final_model.evaluate([X_test, lbp_images_test], y_test)\n",
    "train_evaluation = final_model.evaluate([X_train, lbp_images_train], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 35s 313ms/step - loss: 4.8835 - accuracy: 0.3845\n",
      "909/909 [==============================] - 293s 322ms/step - loss: 0.0242 - accuracy: 0.9961\n"
     ]
    }
   ],
   "source": [
    "test_evaluation = model.evaluate([X_test, lbp_images_test], y_test)\n",
    "train_evaluation = model.evaluate([X_train, lbp_images_train], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 704,
     "status": "ok",
     "timestamp": 1523868120543,
     "user": {
      "displayName": "Łukasz Zawieska",
      "photoUrl": "//lh4.googleusercontent.com/-SOS7Ol5qfEA/AAAAAAAAAAI/AAAAAAAABh4/xJ9cAj7pBag/s50-c-k-no/photo.jpg",
      "userId": "112181072187986880314"
     },
     "user_tz": -120
    },
    "id": "t9sfZi8gUs7I",
    "outputId": "ebdd949b-80ce-4d69-e1ca-3e093abc0bbd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 708,
     "status": "ok",
     "timestamp": 1523868146378,
     "user": {
      "displayName": "Łukasz Zawieska",
      "photoUrl": "//lh4.googleusercontent.com/-SOS7Ol5qfEA/AAAAAAAAAAI/AAAAAAAABh4/xJ9cAj7pBag/s50-c-k-no/photo.jpg",
      "userId": "112181072187986880314"
     },
     "user_tz": -120
    },
    "id": "tgml8vqzUs7M",
    "outputId": "89ff582b-df7f-4678-8399-5973cb55d116"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11444,
     "status": "ok",
     "timestamp": 1523868265564,
     "user": {
      "displayName": "Łukasz Zawieska",
      "photoUrl": "//lh4.googleusercontent.com/-SOS7Ol5qfEA/AAAAAAAAAAI/AAAAAAAABh4/xJ9cAj7pBag/s50-c-k-no/photo.jpg",
      "userId": "112181072187986880314"
     },
     "user_tz": -120
    },
    "id": "32C1wIfwUs7Q",
    "outputId": "d65b253c-eda9-4fec-d65a-3c8f1c9373a5"
   },
   "outputs": [],
   "source": [
    "def predict_classes(model, test_imgs, test_labels, emotions_dict,  batch_size  = 32):    \n",
    "\n",
    "    # Predict class of image using trained model\n",
    "    class_pred = model.predict(test_imgs, batch_size = batch_size)\n",
    "\n",
    "    # Convert vector of zeros and ones to label\n",
    "    labels_pred = np.argmax(class_pred,axis=1)\n",
    "    true_labels = np.argmax(test_labels, axis=1)\n",
    "\n",
    "    # Boolean array that indicates whether the predicted label is the true label\n",
    "    correct = labels_pred == true_labels\n",
    "    \n",
    "    # Converting array of labels into emotion names\n",
    "    pred_emotion_names = pd.Series(labels_pred).map(emotions_dict)\n",
    "    \n",
    "    results = {'Predicted_label': labels_pred, 'Predicted_emotion': pred_emotion_names, 'Is_correct' : correct}\n",
    "    results = pd.DataFrame(results)\n",
    "    return correct, results\n",
    "\n",
    "\n",
    "def visualize_predictions(images_test, orglabel_names, predlabel_names, correct_arr, valid = True):\n",
    "    \n",
    "    if valid == True:\n",
    "        correct = np.array(np.where(correct_arr == True))[0]\n",
    "        # Plot 15 randomly selected and correctly predicted images\n",
    "        show_random(images_test, emotion_nms_org = orglabel_names, emotion_nms_pred = predlabel_names, random = False, indices = correct)\n",
    "    else:\n",
    "        incorrect = np.array(np.where(correct_arr == False))[0]\n",
    "        # Plot 15 randomly selected and wrongly predicted images\n",
    "        show_random(images_test, emotion_nms_org = orglabel_names, emotion_nms_pred = predlabel_names, random = False, indices = incorrect)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct, results_df = predict_classes(model, X_test, y_test, emotions_names, batch_size = 64)\n",
    "results_df['Original_label'] = data['emotion'][32298:].values\n",
    "results_df['True_emotion'] = results_df['Original_label'].map(emotions_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correctly predicted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(images, true_emotions, predicted_emotions, correct, valid=True):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(len(images)):\n",
    "        if correct[i] == valid:  # Filter based on whether prediction is correct or not\n",
    "            count += 1\n",
    "            # Reshape the flattened image to (48, 48)\n",
    "            reshaped_image = images[i].reshape(48, 48)\n",
    "            plt.subplot(5, 5, count)\n",
    "            plt.imshow(reshaped_image, cmap='gray')\n",
    "            plt.title(f'True: {true_emotions[i]}\\nPredicted: {predicted_emotions[i]}')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            if count >= 25:  # Display up to 25 images\n",
    "                break\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Call the function to visualize incorrect predictions\n",
    "visualize_predictions(images_test, results_df['True_emotion'], results_df['Predicted_emotion'], correct, valid=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wronly predicted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(images, true_emotions, predicted_emotions, correct, valid=True):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(len(images)):\n",
    "        if correct[i] == valid:  # Filter based on whether prediction is correct or not\n",
    "            count += 1\n",
    "            # Reshape the flattened image to (48, 48)\n",
    "            reshaped_image = images[i].reshape(48, 48)\n",
    "            plt.subplot(5, 5, count)\n",
    "            plt.imshow(reshaped_image, cmap='gray')\n",
    "            plt.title(f'True: {true_emotions[i]}\\nPredicted: {predicted_emotions[i]}')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            if count >= 25:  # Display up to 25 images\n",
    "                break\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Call the function to visualize incorrect predictions\n",
    "visualize_predictions(images_test, results_df['True_emotion'], results_df['Predicted_emotion'], correct, valid=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_confmat(true_labels, predicted_labels, columns, colour = 'Oranges', size = (20,14)):\n",
    "    \n",
    "    cm = confusion_matrix(true_labels, predicted_labels) \n",
    "    cm_df = pd.DataFrame(cm,\n",
    "    index = [col for col in columns], \n",
    "    columns = [col for col in columns])\n",
    "    plt.figure(figsize=(18,16))\n",
    "    sns.heatmap(cm_df, annot = True, cmap = colour, fmt='g', linewidths=.2)\n",
    "    plt.title('Confusion Matrix', fontsize = 20)\n",
    "    plt.ylabel('True label', fontsize = 18)\n",
    "    plt.xlabel('Predicted label', fontsize = 18)\n",
    "    plt.tick_params(axis='both', labelsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying confusion matrix\n",
    "create_confmat(results_df['Original_label'], results_df['Predicted_label'], ['Angry','Disgust','Fear', 'Happy', 'Sad', 'Surprise', 'Neutral'], colour = 'Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path ke gambar\n",
    "img_path = 'D:/Semester_7/FER-2013/test/fear/PrivateTest_2632530.jpg'\n",
    "\n",
    "# Memuat gambar ke dalam bentuk grayscale\n",
    "test_image = image.load_img(img_path, target_size=(48, 48), color_mode='grayscale')\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "test_image = test_image / 255.0\n",
    "\n",
    "# Melakukan prediksi\n",
    "result = model.predict(test_image)\n",
    "predicted_class = np.argmax(result[0])\n",
    "\n",
    "emotions_names = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n",
    "print(emotions_names)\n",
    "\n",
    "# Menampilkan gambar\n",
    "plt.imshow(test_image[0, :, :, 0], cmap='gray')  # Munculkan gambar grayscale\n",
    "plt.title('Predicted class: {}'.format(predicted_class))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "fer_1st_model.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
